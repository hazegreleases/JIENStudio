# JIET Studio
### The Offline, Unlimited YOLO Training Suite
**Label â†’ Augment â†’ Train â†’ Test. All in one app. Zero cloud dependency.**

![Python](https://img.shields.io/badge/Python-3.8%2B-blue) ![YOLOv11](https://img.shields.io/badge/YOLO-v8%20%7C%20v11-magenta) ![License](https://img.shields.io/badge/License-MIT-green) ![Status](https://img.shields.io/badge/Status-Active-success)

---

## ğŸ¯ The Problem

Training object detection models shouldn't require:
- âŒ Uploading your proprietary data to third-party servers
- âŒ Paying $50/month for "credits" to train on your own data
- âŒ Waiting in cloud queues while GPUs sit idle on your desk
- âŒ Complex terminal commands and YAML file editing
- âŒ Switching between 5 different tools for one workflow

---

## ğŸ’¡ The Solution: JIET Studio

**One desktop app. Complete YOLO workflow. 100% local.**

```
Your Images â†’ Auto-Label (SAM2) â†’ Augment (25+ Filters) â†’ Train (YOLO) â†’ Test â†’ Production Model
                              â†‘_____________________|
                                  (All Offline)
```

---

## ğŸš€ Why JIET Studio Beats The Competition

| Feature | Roboflow | CVAT | Label Studio | JIETStudio |
|---------|----------|------|--------------|-------------|
| **Privacy** | â˜ï¸ Cloud Upload Required | âš™ï¸ Complex Self-Host | âš™ï¸ Complex Self-Host | âœ… **100% Local** |
| **Cost** | ğŸ’° $50-$250/mo | Free (setup hell) | Free (setup hell) | âœ… **Free Forever** |
| **Training** | Limited credits | Not included | Not included | âœ… **Unlimited** |
| **Augmentation** | 15 basic filters | 5 basic filters | External tools | âœ… **25+ Filters + Custom** |
| **Auto-Labeling** | Paid feature | Manual only | External | âœ… **Built-in SAM2** |
| **Setup Time** | 10 mins (+ upload time) | 2-4 hours | 2-4 hours | âœ… **30 seconds** |
| **Labeling Speed** | Click dropdowns | Click dropdowns | Click dropdowns | âœ… **Scroll-Wheel Switching** |
| **Training Control** | Basic params only | N/A | N/A | âœ… **Full YOLO Control** |
| **Inference Testing** | Separate tool | Separate tool | Not included | âœ… **Built-in** |

### Detailed Comparison

#### vs **Roboflow** (Cloud, $$$)
**Roboflow Pros**: Polished UI, good documentation, team features
**Roboflow Cons**: Data leaves your network, expensive at scale, training limited by credits

**JIET Studio Advantage**:
- **Privacy**: Medical/military/proprietary data stays local
- **Cost**: Train 1000 epochs/month or 10/month - same price: $0
- **Speed**: No upload/download bottleneck (100GB dataset? No problem.)

#### vs **CVAT** (Open Source Enterprise)
**CVAT Pros**: Feature-rich, supports video, team collaboration
**CVAT Cons**: Docker + Postgres + Redis setup, no trainingintegration, overkill for solo developers

**JIET Studio Advantage**:
- **Setup**: `python main.py` vs 2 hours of Docker configuration
- **Workflow**: Label â†’ Train in one app vs Label (CVAT) â†’ Export â†’ Train (Terminal)  
- **Simplicity**: Designed for solo devs/small teams, not Fortune 500

#### vs **Label Studio** (Self-Hosted)
**Label Studio Pros**: Supports many annotation types (NLP, audio, etc.)
**Label Studio Cons**: Web-based = setup overhead, no training included, slow for pure object detection

**JIET Studio Advantage**:
- **Focus**: Built ONLY for object detection = streamlined UX
- **Integration**: One-click training from labeled data
- **Performance**: Desktop app = faster canvas rendering for large images

#### vs **Labelme / Make Sense** (Simple Tools)
**Their Pros**: Very simple, quick start
**Their Cons**: Just annotation, no augmentation, no training, no testing

**JIET Studio Advantage**:
- **Complete Workflow**: Annotation is 25% of the job - we handle the other 75%
- **Auto-Labeling**: SAM2 Magic Wand speeds up labeling 5-10x
- **Augmentation**: Don't train on 100 raw images - multiply to 2000+ variants

---

## âœ¨ Features That Make You Faster

### 1. âš¡ **Flow-State Labeling**
Designed for speed, not clicks.

- **Scroll-Wheel Class Switching**: Rotate through classes without moving your hands
- **Magic Wand (SAM2)**: Click object â†’ Auto-labeled bounding box in 0.5s
- **Zoom to Mouse**: `Ctrl+Scroll` exactly where you need it
- **Instant Save**: `Ctrl+S` â†’ Green flash â†’ Next image (zero latency)
- **Organized View**: Auto-groups Labeled/Unlabeled/Negatives/Per-Class

**Result**: Label 100 images in 15 minutes (with Magic Wand) vs 2+ hours manually.

### 2. ğŸ¨ **Industrial Augmentation Engine**
Not just "flip and rotate" - production-grade data augmentation.

**25+ Filters Organized by Category**:
- **Color**: Brightness, Contrast, Exposure, CLAHE, HSV, RGBShift
- **Blur**: Gaussian, Motion, Sharpen, Unsharp Mask
- **Geometric**: Rotate, Flips (H/V), Safe 90Â° rotations
- **Spatial**: RandomCrop, CenterCrop, Bbox-safe resize
- **Noise**: Gaussian, ISO Camera Noise
- **Advanced**: Perspective, Elastic Transform, Grid Distortion, Optical Distortion

**Smart Features**:
- âœ… **Bbox Safety Indicators**: Know which filters preserve bounding boxes
- âœ… **Live Preview**: See augmentations before running
- âœ… **Parameter Validation**: Auto-clamping to safe ranges
- âœ… **Plugin System**: Write custom filters in Python, UI auto-generates controls
- âœ… **Presets**: Light/Medium/Heavy augmentation templates

**Example**:
100 labeled images â†’ 5x augmentation â†’ 500 training images â†’ Better model accuracy

### 3. ğŸ‹ï¸ **One-Click YOLO Training**
Forget `data.yaml` files and terminal commands.

```
1. Click "Training" tab
2. Select model (YOLOv8/v11, nano to x10)
3. Set epochs, batch size, image size
4. Click "START TRAINING"
5. Watch live progress with GPU monitoring
```

**Behind the scenes**:
- Auto-generates proper folder structure
- Creates data.yaml configuration
- Splits train/val sets automatically
- **Unloads inference models** to free 500MB+ GPU RAM
- Real-time CPU/GPU/RAM monitoring
- **Clears VRAM/RAM after completion** (even if stopped manually)
- **Reloads Magic Wand after training** for seamless workflow

**Result**: 50-epoch training starts in 5 seconds, not 30 minutes of setup.

### 4. ğŸ” **Built-In Inference Testing**
Train â†’ Test â†’ Iterate without leaving the app.

- **Image mode**: Batch test on folders
- **Video mode**: Upload MP4/AVI and see detections
- **Webcam mode**: Real-time testing
- **Model switching**: Compare v8 vs v11, nano vs large instantly
- **Confidence tuning**: Live slider to find optimal threshold

**Result**: Catch bad models before deploying to production.

---

## ğŸ“¦ Installation

### Prerequisites
- **Python 3.8+** (3.10 recommended)
- **Windows** (macOS/Linux support planned)
- **GPU** (NVIDIA RTX recommended, CPU works but slower)

### Quick Start
```bash
# Clone
git clone https://github.com/hazegreleases/JIETStudio.git
cd JIETStudio

# Run (dependencies auto-install on first launch)
python main.py
```

**First Run**:
1. Dependencies install automatically (~2 minutes)
2. App opens â†’ Create or load project
3. Import images â†’ Start labeling

**That's it.** No Docker, no databases, no config files.

---

## ğŸ® Workflow Example

### Scenario: Training a Product Defect Detector

```
Day 1: Data Collection & Labeling
â”œâ”€ Take 200 photos of products (good + defective)
â”œâ”€ Create project in JIET Studio
â”œâ”€ Import 200 images
â”œâ”€ Define classes: "scratch", "dent", "crack"
â”œâ”€ Use Magic Wand (SAM2) to auto-label obvious defects
â”œâ”€ Manually adjust and label edge cases
â””â”€ **Time**: 1.5 hours total

Day 1: Augmentation
â”œâ”€ Open "Augmentation" tab
â”œâ”€ Add filters: Rotate(Â±15Â°), Brightness(0.2), Noise, Perspective
â”œâ”€ Set "5 augmentations per image"
â”œâ”€ Click "Run" â†’ 1000 training images generated
â””â”€ **Time**: 5 minutes

Day 1: Training
â”œâ”€ Open "Training" tab
â”œâ”€ Select YOLOv8s, 50 epochs, 640px, batch 16
â”œâ”€ Click "START TRAINING"
â”œâ”€ Grab coffee while GPU works
â””â”€ **Time**: ~20 minutes (RTX 3060)

Day 1: Testing
â”œâ”€ Open "Inference" tab
â”œâ”€ Load trained model from runs/detect/train/weights/best.pt
â”œâ”€ Test on validation images
â”œâ”€ Adjust confidence threshold to reduce false positives
â”œâ”€ Test on webcam with real products
â””â”€ **Time**: 10 minutes

Result: Production-ready model in <2 hours total work
```

---

## âŒ¨ï¸ Power User Shortcuts

Master these to achieve **Flow State**:

| Action | Shortcut | Pro Tip |
|--------|----------|---------|
| **Save & Next** | `Ctrl + S` | Instant save |
| **Switch Class** | `Scroll Wheel` | Keep hand on mouse |
| **Zoom** | `Ctrl + Scroll` | Zooms to mouse position |
| **Delete Box** | `Del` | Select box first |
| **Delete Image** | `Ctrl + Shift + D` | Removes bad images instantly |
| **Magic Wand** | Click Star icon â†’ Click object | Faster than manual boxing |
| **Undo** | `Ctrl + Z` | Works everywhere |
| **Redo** | `Ctrl + Y` | Works everywhere |

**Flow State Goal**: Never lift hands from keyboard+mouse. No clicking dropdowns or menus.

---


## ğŸ”Œ Plugin System: Custom Augmentation Filters

### Example: Sepia Filter
```python
# my_sepia_filter.py
from app.core.augmentation.base import AugmentationEffect, ParamSpec, FilterCategory
import albumentations as A

class SepiaEffect(AugmentationEffect):
    \"\"\"Applies vintage sepia tone.\"\"\"
    
    category = FilterCategory.COLOR
    bbox_safe = True
    
    def __init__(self, intensity=0.5, probability=0.5, enabled=True):
        super().__init__(probability, enabled)
        self.intensity = intensity
    
    def get_transform(self):
        # Use albumentations ToSepia
        return A.ToSepia(p=self.probability)
    
    def get_param_specs(self):
        return {
            'intensity': ParamSpec(
                value=self.intensity,
                min_val=0.0,
                max_val=1.0,
                param_type='float',
                description='Sepia intensity'
            )
        }
    
    def set_params(self, params):
        if 'intensity' in params:
            self.intensity = float(params['intensity'])
```

**Usage**:
1. Save as `my_sepia_filter.py`
2. In Augmentation tab â†’ Click "Import Filter"
3. Select file â†’ Filter appears in dropdown **with auto-generated UI slider**

See [FILTER_GUIDE.md](docs/custom_filters.md) for full documentation.

---

## ğŸ¤ Contributing

We welcome contributions! This project is actively maintained.

**How to contribute**:
- ğŸ› **Found a bug?** Open an issue with reproduction steps
- ğŸ’¡ **Feature idea?** Discuss in Issues before implementing
- ğŸ¨ **Created a cool filter?** Submit PR to `app/core/augmentation/filters/community/`
- ğŸ“– **Improved docs?** PRs always welcome

**Development Setup**:
```bash
git clone https://github.com/hazegreleases/JIETStudio.git
cd JIETStudio
pip install -r requirements.txt
python main.py
```

**Code Style**: Follow existing patterns, add docstrings, keep it simple.

---

## ğŸ›£ï¸ Roadmap

**Current Version**: v0.8 (Active Development)

**Planned Features**:
- [ ] macOS/Linux support
- [ ] Multi-GPU training
- [ ] Instance segmentation (polygons)
- [ ] Export to ONNX/TFLite
- [ ] Dataset versioning (git-like diffs)
- [ ] Batch auto-labeling with confidence filtering
- [ ] Training templates (presets for common scenarios)
- [ ] Model comparison dashboard

**Recently Added** âœ…:
- [x] SAM2 Magic Wand auto-labeling
- [x] 25+ augmentation filters
- [x] Memory management during training
- [x] Organized labeling view
- [x] Plugin system for custom filters

---

## ğŸ“Š Performance Notes

**Hardware Recommendations**:
- **CPU**: 4+ cores (Intel i5/AMD Ryzen 5 or better)
- **RAM**: 8GB minimum, 16GB+ recommended
- **GPU**: RTX 2060 or better (6GB+ VRAM)
- **Storage**: SSD for faster image loading

**Benchmarks** (RTX 3060, 100 images, 50 epochs):
- **YOLOv8n**: ~5 minutes
- **YOLOv8s**: ~10 minutes
- **YOLOv8m**: ~20 minutes
- **YOLO11x**: ~45 minutes

**Memory Management**:
- SAM2 model consumes ~450MB VRAM
- Training automatically unloads SAM to free memory
- Post-training, SAM reloads automatically for continued labeling

---

## ğŸ”’ Privacy & Data Security

**100% Offline Operation**:
- âœ… No telemetry, no analytics, no "phone home"
- âœ… All data stays on your machine
- âœ… No account creation required
- âœ… Works without internet connection (after initial setup)

**Perfect for**:
- Medical imaging (HIPAA compliance)
- Military/defense applications
- Proprietary industrial inspection
- Privacy-sensitive research

---

## â“ FAQ

**Q: Does it work without GPU?**  
A: Yes, but training is 10-50x slower. Labeling and augmentation are CPU-friendly.

**Q: Can I use my own YOLO model?**  
A: Yes, click "Import Model" in Training tab and select your `.pt` file.

**Q: What image formats are supported?**  
A: JPG, PNG, BMP, TIFF. Labels are YOLO format `.txt` files.

**Q: Can I export to other formats (COCO, Pascal VOC)?**  
A: Not yet - on roadmap. Currently YOLO format only.

**Q: How do I deploy the trained model?**  
A: Use `runs/detect/train/weights/best.pt` with Ultralytics library or export to ONNX.

**Q: Is multi-class detection supported?**  
A: Yes, unlimited classes. Define in project setup.

**Q: Linearity?**  
A: MIT License - free for commercial use.

---

## ğŸ·ï¸ Keywords

`yolo`, `yolov8`, `yolov11`, `object-detection`, `computer-vision`, `labeling-tool`, `image-annotation`, `data-augmentation`, `training-gui`, `ultralytics`, `offline-ml`, `auto-labeling`, `sam2`, `local-training`, `desktop-app`, `python-gui`, `ml-workflow`, `deep-learning`, `pytorch`

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE)

**TLDR**: Use it, modify it, sell products built with it. Just don't sue us.

---

<div align="center">

**Built by developers who got tired of cloud lock-in.**

[â­ Star this repo](https://github.com/hazegreleases/JIETStudio) | [ğŸ› Report Bug](https://github.com/hazegreleases/JIETStudio/issues) | [ğŸ’¡ Request Feature](https://github.com/hazegreleases/JIETStudio/issues)

</div>
